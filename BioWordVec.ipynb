{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nlei1/nlp-notebooks/blob/main/BioWordVec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MtBrzqzqkG0j"
      },
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd \n",
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from scipy import stats\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as pyplot\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50c90mPzkHbV",
        "outputId": "920a2e86-be11-4181-c127-d475f9a3f118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-03 15:34:39--  https://ftp.ncbi.nlm.nih.gov/pub/lu/Suppl/BioSentVec/BioWordVec_PubMed_MIMICIII_d200.vec.bin\n",
            "Resolving ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)... 165.112.9.228, 165.112.9.230, 2607:f220:41e:250::11, ...\n",
            "Connecting to ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|165.112.9.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13451441787 (13G) [application/octet-stream]\n",
            "Saving to: ‘/root/input/BioWordVec_PubMed_MIMICIII_d200.vec.bin’\n",
            "\n",
            "BioWordVec_PubMed_M 100%[===================>]  12.53G  51.9MB/s    in 5m 37s  \n",
            "\n",
            "2022-08-03 15:40:16 (38.1 MB/s) - ‘/root/input/BioWordVec_PubMed_MIMICIII_d200.vec.bin’ saved [13451441787/13451441787]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -P /root/input/ -c 'https://ftp.ncbi.nlm.nih.gov/pub/lu/Suppl/BioSentVec/BioWordVec_PubMed_MIMICIII_d200.vec.bin'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hl3Kkw6Km67U"
      },
      "outputs": [],
      "source": [
        "model = gensim.models.KeyedVectors.load_word2vec_format(\n",
        "     '/root/input/BioWordVec_PubMed_MIMICIII_d200.vec.bin',\n",
        "      binary=True,\n",
        "      limit=int(2E6)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj00Z8NSWpVI",
        "outputId": "1a2f7c55-03f4-4148-b73b-3a82f4ecb1a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path = '/content/drive/My Drive/embeddings'\n",
        "# word_vectors = model.wv\n",
        "\n",
        "# # save as KeyedVectors\n",
        "# from gensim.models import KeyedVectors\n",
        "# word_vectors.save(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Do18-hXWy7M",
        "outputId": "69308e69-808d-4c05-c42e-a2d4d2b41ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qEdZZXZpoIng"
      },
      "outputs": [],
      "source": [
        "url  = 'https://raw.githubusercontent.com/nlei1/csvs-for-proj/main/drugs-side-effects3.csv'\n",
        "df = pd.read_csv(url, header=None, error_bad_lines=False)\n",
        "insomnia_drug_names = df[0].tolist()\n",
        "ind_dct = {k: v for v, k in enumerate(insomnia_drug_names)}\n",
        "\n",
        "def get_words(drug_name):\n",
        "  return [incom for incom in df.iloc[ind_dct[drug_name]] if str(incom) != 'nan']\n",
        "\n",
        "def get_embeddings(words_lst):\n",
        "  # takes in a name and returns a lst of embeddings of drug and its related words\n",
        "  embeddings = []\n",
        "  for item in words_lst:\n",
        "    embeddings.append(model[item])\n",
        "  return embeddings\n",
        "\n",
        "def get_pca(embeddings, n_components):\n",
        "  pca = PCA(n_components)\n",
        "  pca_result = pca.fit_transform(embeddings)\n",
        "  post_pca = pd.DataFrame(pca_result, columns = ['x','y'])\n",
        "  return post_pca\n",
        "\n",
        "def get_tsne(embeddings, p_perplexity, p_n_iter, n_components):\n",
        "  tsne = TSNE(n_components, perplexity=p_perplexity, n_iter=p_n_iter)\n",
        "  tsne_result = tsne.fit_transform(embeddings)\n",
        "  post_tsne = pd.DataFrame(tsne_result, columns = ['x','y'])\n",
        "  return post_tsne\n",
        "\n",
        "def plot_with_labels(drug_name, pca=True, p_perplexity=1, p_n_iter=1000, n_components=2):\n",
        "  words_lst = get_words(drug_name)\n",
        "  embeddings_lst = get_embeddings(words_lst)\n",
        "  if pca:\n",
        "    post_reduction = get_pca(embeddings_lst, n_components)\n",
        "  else:\n",
        "    post_reduction = get_tsne(embeddings_lst, p_perplexity, p_n_iter, n_components)\n",
        "  post_reduction_annotated = post_reduction.join(pd.DataFrame(words_lst, columns=['label']))\n",
        "  title_str = drug_name + (\": PCA\" if pca else \": TSNE\")\n",
        "  ax = post_reduction_annotated.plot(x='x',y='y',kind='scatter',figsize=(10,10), title=title_str)\n",
        "  post_reduction_annotated[['x','y','label']].apply(lambda x: ax.text(*x),axis=1)\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "\n",
        "def plot_insomnia_drugs():\n",
        "  for drug in insomnia_drug_names:\n",
        "    plot_with_labels(drug)\n",
        "    plot_with_labels(drug, False)\n",
        "\n",
        "def get_similarity_table(n=20):\n",
        "  result_lst = []\n",
        "  for drug in insomnia_drug_names:\n",
        "    result_lst.append(pd.DataFrame(model.most_similar(positive=[drug], topn=n), columns=['name (' + drug + \")\", 'similarity (' + drug + \")\"]))\n",
        "  return pd.concat(result_lst, axis=1, join=\"inner\")\n",
        "\n",
        "def get_effects_table(n=20):\n",
        "  result_lst = []\n",
        "  for drug in insomnia_drug_names:\n",
        "    result_lst.append(pd.DataFrame(model.most_similar(positive=[drug, 'effects'], negative=['medication'], topn=n), columns=['name (' + drug + \")\", 'similarity (' + drug + \")\"]))\n",
        "  return pd.concat(result_lst, axis=1, join=\"inner\")\n",
        "\n",
        "def forms_of_words_analysis():\n",
        "  forms_of_words_url = 'https://raw.githubusercontent.com/nlei1/csvs-for-proj/main/forms-of-words.csv'\n",
        "  forms_of_words_df = pd.read_csv(forms_of_words_url, header=None, error_bad_lines=False)\n",
        "  word_lst = []\n",
        "  for index, row in forms_of_words_df.iterrows():\n",
        "    word_lst += (row.dropna()).tolist()\n",
        "  new_lst = []\n",
        "  for thing in word_lst:\n",
        "    if thing in model.wv.vocab:\n",
        "      new_lst.append(thing)\n",
        "  embeddings_lst = get_embeddings(new_lst)\n",
        "  post_reduction = get_tsne(embeddings_lst, p_perplexity=1, p_n_iter=1000, n_components=2)\n",
        "  post_reduction_annotated = post_reduction.join(pd.DataFrame(new_lst, columns=['label']))\n",
        "  ax = post_reduction_annotated.plot(x='x',y='y',kind='scatter',figsize=(10,10), title='TSNE')\n",
        "  post_reduction_annotated[['x','y','label']].apply(lambda x: ax.text(*x),axis=1)\n",
        "  post_reduction = get_pca(embeddings_lst, n_components=2)\n",
        "  post_reduction_annotated = post_reduction.join(pd.DataFrame(new_lst, columns=['label']))\n",
        "  ax = post_reduction_annotated.plot(x='x',y='y',kind='scatter',figsize=(10,10), title='PCA')\n",
        "  post_reduction_annotated[['x','y','label']].apply(lambda x: ax.text(*x),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TW2PT7UipRld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e33189-f0e6-494a-bf13-508cf563ea3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BioSimLex: SpearmanrResult(correlation=0.7205657589428461, pvalue=6.310315624661459e-153)\n",
            "BioSimVerb: SpearmanrResult(correlation=0.49286944052215226, pvalue=3.817606785201803e-62)\n",
            "UMNSRS-REL: SpearmanrResult(correlation=0.5722957648037825, pvalue=1.9411914157533975e-47)\n",
            "UMNSRS-SIM: SpearmanrResult(correlation=0.6319125266711013, pvalue=5.568675126110056e-59)\n",
            "Novel Intrinsic Task: 0.16147756576538086\n"
          ]
        }
      ],
      "source": [
        "import statistics\n",
        "import scipy\n",
        "import torch\n",
        "\n",
        "biosimlex_url = 'https://raw.githubusercontent.com/cambridgeltl/bio-simverb/master/wvlib/word-similarities/bio-simlex/Bio-SimLex.txt'\n",
        "biosimverb_url = 'https://raw.githubusercontent.com/cambridgeltl/bio-simverb/master/wvlib/word-similarities/bio-simverb/Bio-SimVerb.txt'\n",
        "umnsrs_rel_url = 'https://raw.githubusercontent.com/cambridgeltl/bio-simverb/master/wvlib/word-similarities/UMNSRS/UMNSRS-rel.txt'\n",
        "umnsrs_sim_url = 'https://raw.githubusercontent.com/cambridgeltl/bio-simverb/master/wvlib/word-similarities/UMNSRS/UMNSRS-sim.txt'\n",
        "\n",
        "tensors_dict = {}\n",
        "\n",
        "def sim_matrix(a, b, eps=1e-8):\n",
        "  \"\"\"\n",
        "  added eps for numerical stability\n",
        "  \"\"\"\n",
        "  a_n, b_n = a.norm(dim=1)[:, None], b.norm(dim=1)[:, None]\n",
        "  a_norm = a / torch.max(a_n, eps * torch.ones_like(a_n))\n",
        "  b_norm = b / torch.max(b_n, eps * torch.ones_like(b_n))\n",
        "  sim_mt = torch.mm(a_norm, b_norm.transpose(0, 1))\n",
        "  return sim_mt.item()\n",
        "\n",
        "def retrieve_embedding(item):\n",
        "  lst = model[item]\n",
        "  return torch.tensor([lst])\n",
        "\n",
        "def evaluate(filename, num_rows_eval=50): \n",
        "  if filename.endswith(\".csv\"):\n",
        "    data = (pd.read_csv(filename, sep=\",\")).iloc[:num_rows_eval]\n",
        "  else:\n",
        "    data = pd.read_csv(filename, sep=\"\\t\")\n",
        "  human_similarity = []\n",
        "  model_similarity = []\n",
        "  counter = 0\n",
        "  for i in data.iloc[:, 0:2].index:\n",
        "    word1, word2 = data.iloc[i, 0], data.iloc[i, 1]\n",
        "    if not ((word1 in model) and (word2 in model)):\n",
        "      continue\n",
        "    else:\n",
        "      model_similarity.append(sim_matrix(retrieve_embedding(word1), retrieve_embedding(word2)))\n",
        "      human_similarity.append(float(data.iloc[i, 2]))\n",
        "\n",
        "  return scipy.stats.spearmanr(human_similarity, model_similarity)# , model_similarity\n",
        "\n",
        "def novel_intrinsic_eval():\n",
        "  group_a = [\"zolpidem\",\"eszopiclone\",\"zaleplon\",\"trazodone\",\"amitriptyline\",\"mirtazapine\",\"doxepin\",\"lorazepam\",\"clonazepam\",\"temazepam\",\"triazolam\",\"suvorexant\",\"lemborexant\",\"melatonin\"]\n",
        "  group_b = [\"atorvastatin\",\"acetaminophen\",\"ibuprofen\",\"levothyroxine\",\"lisinopril\",\"metformin\",\"metoprolol\",\"amlodipine\",\"albuterol\",\"omeprazole\",\"losartan\",\"gabapentin\",\"hydrochlorothiazide\",\"furosemide\"]\n",
        "  thetas = []\n",
        "  for word1 in insomnia_drug_names:\n",
        "    group1_scores = []\n",
        "    group2_scores = []\n",
        "    # group 1: similar\n",
        "    for word2 in group_a:\n",
        "      if not ((word1 in model) and (word2 in model)):\n",
        "        # print(word1)\n",
        "        # print(word2)\n",
        "        continue\n",
        "      else:\n",
        "        group1_scores.append(sim_matrix(retrieve_embedding(word1), retrieve_embedding(word2)))\n",
        "\n",
        "    # group 2: different\n",
        "    for word2 in group_b:\n",
        "      if not ((word1 in model) and (word2 in model)):\n",
        "        # print(word1)\n",
        "        # print(word2)\n",
        "        continue\n",
        "      else:\n",
        "        group2_scores.append(sim_matrix(retrieve_embedding(word1), retrieve_embedding(word2)))\n",
        "    \n",
        "    if group1_scores and group2_scores:\n",
        "      thetas.append(statistics.median(group1_scores) - statistics.median(group2_scores))\n",
        "  return statistics.median(thetas)\n",
        "\n",
        "def run_eval():\n",
        "  print(\"BioSimLex:\", evaluate(biosimlex_url))\n",
        "  print(\"BioSimVerb:\", evaluate(biosimverb_url))\n",
        "  print(\"UMNSRS-REL:\", evaluate(umnsrs_rel_url))\n",
        "  print(\"UMNSRS-SIM:\", evaluate(umnsrs_sim_url))\n",
        "  print(\"Novel Intrinsic Task:\", novel_intrinsic_eval())\n",
        "\n",
        "run_eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "242E8XhSqblW"
      },
      "outputs": [],
      "source": [
        "evaluate(biosimverb_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLII1JjBnUMB"
      },
      "outputs": [],
      "source": [
        "plot_insomnia_drugs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAxx8KJFwol0"
      },
      "outputs": [],
      "source": [
        "get_similarity_table()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz0DT0FNwqyK"
      },
      "outputs": [],
      "source": [
        "get_effects_table()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlSowcqGhbHn"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/My Drive/biowordvec_similarity.csv'\n",
        "tmp_df = get_similarity_table(1000)\n",
        "\n",
        "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
        "  tmp_df.to_csv(f)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS5MUoPbmq_U"
      },
      "outputs": [],
      "source": [
        "# sensitivity\n",
        "\n",
        "new_url = \"https://raw.githubusercontent.com/nlei1/csvs-for-proj/main/drugs-side-effects-4.csv\"\n",
        "new_df = pd.read_csv(new_url, header=None, error_bad_lines=False)\n",
        "insomnia_drug_names2 = new_df[0].tolist()\n",
        "ind_dct2 = {k: v for v, k in enumerate(insomnia_drug_names2)}\n",
        "\n",
        "def get_words2(drug_name):\n",
        "  return [incom for incom in new_df.iloc[ind_dct2[drug_name]] if str(incom) != 'nan']\n",
        "\n",
        "def plot_with_labels2(drug_name, pca=True, p_perplexity=1, p_n_iter=1000, n_components=2):\n",
        "  words_lst = get_words2(drug_name)\n",
        "  embeddings_lst = get_embeddings(words_lst)\n",
        "  if pca:\n",
        "    post_reduction = get_pca(embeddings_lst, n_components)\n",
        "  else:\n",
        "    post_reduction = get_tsne(embeddings_lst, p_perplexity, p_n_iter, n_components)\n",
        "  post_reduction_annotated = post_reduction.join(pd.DataFrame(words_lst, columns=['label']))\n",
        "  title_str = drug_name + (\": PCA\" if pca else \": TSNE\")\n",
        "  ax = post_reduction_annotated.plot(x='x',y='y',kind='scatter',figsize=(10,10), title=title_str)\n",
        "  post_reduction_annotated[['x','y','label']].apply(lambda x: ax.text(*x),axis=1)\n",
        "\n",
        "def plot_insomnia_drugs2():\n",
        "  for drug in insomnia_drug_names2:\n",
        "    plot_with_labels2(drug)\n",
        "    plot_with_labels2(drug, False)\n",
        "\n",
        "plot_insomnia_drugs2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bu02Lg29pYgm"
      },
      "outputs": [],
      "source": [
        "words_lst = df[0].tolist() + ['atorvastatin', 'fluvastatin', 'lovastatin', 'pravastatin']\n",
        "embeddings_lst = get_embeddings(words_lst)\n",
        "post_reduction = get_pca(embeddings_lst, n_components=2)\n",
        "post_reduction_annotated = post_reduction.join(pd.DataFrame(words_lst, columns=['label']))\n",
        "ax = post_reduction_annotated.plot(x='x',y='y',kind='scatter',figsize=(10,10))\n",
        "post_reduction_annotated[['x','y','label']].apply(lambda x: ax.text(*x),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oGFOuiEpcDr"
      },
      "outputs": [],
      "source": [
        "words_lst = df[0].tolist() + ['atorvastatin', 'fluvastatin', 'lovastatin', 'pravastatin']\n",
        "embeddings_lst = get_embeddings(words_lst)\n",
        "post_reduction = get_tsne(embeddings_lst, p_perplexity=1, p_n_iter=1000, n_components=2)\n",
        "post_reduction_annotated = post_reduction.join(pd.DataFrame(words_lst, columns=['label']))\n",
        "ax = post_reduction_annotated.plot(x='x',y='y',kind='scatter',figsize=(10,10))\n",
        "post_reduction_annotated[['x','y','label']].apply(lambda x: ax.text(*x),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67x22UUEP2CT"
      },
      "outputs": [],
      "source": [
        "forms_of_words_analysis()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUYLNXjtQxDP"
      },
      "outputs": [],
      "source": [
        "similarities = model.wv.evaluate_word_pairs('/content/Bio-SimLex.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yf4gJlfAi1fn"
      },
      "outputs": [],
      "source": [
        "similarities"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "BioWordVec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOkRCLM/RMmM5/N7avESjM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}